{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Enhancement of SIFT/RANSAC Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import * # ⚠️⚠️ The functions in utils.py are not correct.\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation # If the module is not found, run `pip install scipy` in this .ipynb in a separate code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Training Labels\n",
    "\n",
    "### Conversion of Net Transformation to Incremental Transformations\n",
    "⚠️⚠️ The conversion is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data, which contains net transformations.\n",
    "PATH_TO_INPUT_FILE = \"train_labels_one_chain_only.csv\"\n",
    "PATH_TO_OUTPUT_FILE = \"nn_Y.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH_TO_INPUT_FILE)\n",
    "\n",
    "# Create a new CSV file.\n",
    "with open(PATH_TO_OUTPUT_FILE, \"w\") as f:\n",
    "\n",
    "    # Write the first row of data in df to the new CSV file.\n",
    "    df.iloc[[0]].to_csv(f, index=False)\n",
    "\n",
    "    # Iterate through the rows of the dataframe, and calculate the incremental transformations.\n",
    "    for i in range(1, 100):\n",
    "        # Analogy: When i = 5, we wish to calculate the transformation which brings image 5 to image 4.\n",
    "        # 05 -> 04 can be calculated by applying 05 -> 00, then 00 -> 04.\n",
    "\n",
    "        curr_transformation_row = df.iloc[i]   # 05 -> 00\n",
    "        prev_transformation_row = df.iloc[i-1] # 04 -> 00\n",
    "\n",
    "        chain_id = curr_transformation_row[\"chain_id\"]\n",
    "\n",
    "        curr_R = np.array([curr_transformation_row[\"qw\"], curr_transformation_row[\"qx\"], curr_transformation_row[\"qy\"], curr_transformation_row[\"qz\"]])\n",
    "        curr_T = np.array([curr_transformation_row[\"x\"], curr_transformation_row[\"y\"], curr_transformation_row[\"z\"]])\n",
    "\n",
    "        prev_R = np.array([prev_transformation_row[\"qw\"], prev_transformation_row[\"qx\"], prev_transformation_row[\"qy\"], prev_transformation_row[\"qz\"]])\n",
    "        prev_T = np.array([prev_transformation_row[\"x\"], prev_transformation_row[\"y\"], prev_transformation_row[\"z\"]])\n",
    "\n",
    "        # Calculate 00 -> 04.\n",
    "        inv_prev_R, inv_prev_T = calculate_inverse_transformation(prev_R, prev_T)\n",
    "\n",
    "        # Calculate 05 -> 04.\n",
    "        R_incremental, T_incremental = compose_transformations(curr_R, curr_T, inv_prev_R, inv_prev_T)\n",
    "\n",
    "        # Write the incremental transformations to the new CSV file.\n",
    "        f.write(f\"{chain_id},{i},{T_incremental[0]},{T_incremental[1]},{T_incremental[2]},{R_incremental[0]},{R_incremental[1]},{R_incremental[2]},{R_incremental[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Sanity Check) Conversion Back to Net Transformations\n",
    "Hopefully, the file we generate `PATH_TO_SANITY_CHECK_FILE` has similar transformations as the `PATH_TO_INPUT_FILE`.\n",
    "\n",
    "Currently, the rotational components are reverse-engineered from the net transformations correctly! 🎉\n",
    "\n",
    "However, the translational components are not. 🫤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SANITY_CHECK_FILE = \"train_labels_sanity_check.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH_TO_OUTPUT_FILE)\n",
    "\n",
    "# Create a new CSV file.\n",
    "with open(PATH_TO_SANITY_CHECK_FILE, \"w\") as f:\n",
    "\n",
    "    # Write the first row of data in df to the new CSV file.\n",
    "    df.iloc[[0]].to_csv(f, index=False)\n",
    "\n",
    "    # Iterate through the rows of the dataframe, and calculate the net transformation.\n",
    "    T_net = np.zeros((3))\n",
    "    R_net = np.array([1, 0, 0, 0])\n",
    "\n",
    "    for i in range(1, 100):\n",
    "        curr_row = df.iloc[i]\n",
    "        chain_id = curr_row[\"chain_id\"]\n",
    "\n",
    "        T_incremental = np.array([curr_row[\"x\"], curr_row[\"y\"], curr_row[\"z\"]])\n",
    "        R_incremental = np.array([curr_row[\"qw\"], curr_row[\"qx\"], curr_row[\"qy\"], curr_row[\"qz\"]])\n",
    "\n",
    "        R_net, T_net = compose_transformations(R_incremental, T_incremental, R_net, T_net)\n",
    "\n",
    "        # Write the net transformations to the new CSV file.\n",
    "        f.write(f\"{chain_id},{i},{T_net[0]},{T_net[1]},{T_net[2]},{R_net[0]},{R_net[1]},{R_net[2]},{R_net[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SIFT, BFMatcher, RANSAC to Compute Transformations\n",
    "SIFT (Scale Invariant Feature Transform) detects features.\n",
    "\n",
    "BFMatcher (Brute-Force Matcher) matches features between two images.\n",
    "\n",
    "RANSAC (RANdom SAmple Consensus) estimates the transformation between two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAIN_ID = '0ef0533373'\n",
    "ABSOLUTE_PATH_TO_FOLDER = os.path.abspath(os.path.join('..', 'data', 'images', CHAIN_ID))\n",
    "\n",
    "images = []\n",
    "for i in range(0, 100):\n",
    "    PATH_TO_IMAGE = os.path.join(ABSOLUTE_PATH_TO_FOLDER, f\"{i:03}\" + \".png\")\n",
    "    img = cv.imread(PATH_TO_IMAGE)\n",
    "    images.append(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Transformations\n",
    "The between-image transformations are computed.\n",
    "\n",
    "We wish to throw these into a neural network to adjust their values, especially for the translational components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From i = 01 to i = 00, 44 keypoints were detected in the (i+1)th image, and 39 keypoints were detected in the ith image.\n",
      "From i = 01 to i = 00, ΔR = [ 0.99998  0.00174 -0.00213 -0.00572], ΔT = [-0.00495  0.01767  0.99983]\n",
      "From i = 02 to i = 01, 54 keypoints were detected in the (i+1)th image, and 44 keypoints were detected in the ith image.\n",
      "From i = 02 to i = 01, ΔR = [ 0.99991 -0.00036  0.00891 -0.01002], ΔT = [ 0.01507 -0.00149  0.99989]\n",
      "From i = 03 to i = 02, 45 keypoints were detected in the (i+1)th image, and 54 keypoints were detected in the ith image.\n",
      "From i = 03 to i = 02, ΔR = [ 0.99978  0.00306 -0.00377  0.02055], ΔT = [-0.00613  0.00377  0.99997]\n",
      "From i = 04 to i = 03, 54 keypoints were detected in the (i+1)th image, and 45 keypoints were detected in the ith image.\n",
      "From i = 04 to i = 03, ΔR = [ 0.85204 -0.20243 -0.06348  0.47857], ΔT = [ 0.43006  0.08629 -0.89867]\n",
      "From i = 05 to i = 04, 61 keypoints were detected in the (i+1)th image, and 54 keypoints were detected in the ith image.\n",
      "From i = 05 to i = 04, ΔR = [ 0.99984  0.00015  0.00364  0.01751], ΔT = [-0.0011   0.00864 -0.99996]\n",
      "From i = 06 to i = 05, 66 keypoints were detected in the (i+1)th image, and 61 keypoints were detected in the ith image.\n",
      "From i = 06 to i = 05, ΔR = [ 0.99993 -0.00056 -0.00517 -0.01035], ΔT = [-0.00263 -0.00571 -0.99998]\n",
      "From i = 07 to i = 06, 49 keypoints were detected in the (i+1)th image, and 66 keypoints were detected in the ith image.\n",
      "From i = 07 to i = 06, ΔR = [ 0.99902 -0.00033 -0.00181 -0.04416], ΔT = [ 0.0043  -0.02527 -0.99967]\n",
      "From i = 08 to i = 07, 55 keypoints were detected in the (i+1)th image, and 49 keypoints were detected in the ith image.\n",
      "From i = 08 to i = 07, ΔR = [ 0.99948  0.00059  0.00014 -0.03235], ΔT = [ 0.01318  0.00392  0.99991]\n",
      "From i = 09 to i = 08, 56 keypoints were detected in the (i+1)th image, and 55 keypoints were detected in the ith image.\n",
      "From i = 09 to i = 08, ΔR = [ 0.99996 -0.00294  0.00872  0.00036], ΔT = [-0.00501 -0.001   -0.99999]\n",
      "From i = 10 to i = 09, 55 keypoints were detected in the (i+1)th image, and 56 keypoints were detected in the ith image.\n",
      "From i = 10 to i = 09, ΔR = [ 0.99946 -0.00176  0.00012  0.03277], ΔT = [ 0.01444  0.0064  -0.99988]\n",
      "From i = 11 to i = 10, 45 keypoints were detected in the (i+1)th image, and 55 keypoints were detected in the ith image.\n",
      "From i = 11 to i = 10, ΔR = [ 0.99997  0.00133 -0.0007   0.007  ], ΔT = [ 0.01364  0.00773 -0.99988]\n",
      "From i = 12 to i = 11, 61 keypoints were detected in the (i+1)th image, and 45 keypoints were detected in the ith image.\n",
      "From i = 12 to i = 11, ΔR = [ 0.99997 -0.00009 -0.00479 -0.00618], ΔT = [-0.00529 -0.01356  0.99989]\n",
      "From i = 13 to i = 12, 52 keypoints were detected in the (i+1)th image, and 61 keypoints were detected in the ith image.\n",
      "From i = 13 to i = 12, ΔR = [ 0.99991  0.00137  0.00511 -0.01205], ΔT = [-0.00068 -0.00193  1.     ]\n",
      "From i = 14 to i = 13, 56 keypoints were detected in the (i+1)th image, and 52 keypoints were detected in the ith image.\n",
      "From i = 14 to i = 13, ΔR = [ 0.99996 -0.00086 -0.00459 -0.00781], ΔT = [ 0.01269  0.00598 -0.9999 ]\n",
      "From i = 15 to i = 14, 50 keypoints were detected in the (i+1)th image, and 56 keypoints were detected in the ith image.\n",
      "From i = 15 to i = 14, ΔR = [ 0.2005   0.42735  0.88158 -0.00047], ΔT = [-0.08636  0.05741  0.99461]\n",
      "From i = 16 to i = 15, 69 keypoints were detected in the (i+1)th image, and 50 keypoints were detected in the ith image.\n",
      "From i = 16 to i = 15, ΔR = [ 0.99955  0.00073 -0.00389 -0.02962], ΔT = [-0.00678  0.00257  0.99997]\n",
      "From i = 17 to i = 16, 75 keypoints were detected in the (i+1)th image, and 69 keypoints were detected in the ith image.\n",
      "From i = 17 to i = 16, ΔR = [ 0.99994 -0.00434 -0.00141 -0.00962], ΔT = [ 0.01052  0.00487  0.99993]\n",
      "From i = 18 to i = 17, 63 keypoints were detected in the (i+1)th image, and 75 keypoints were detected in the ith image.\n",
      "From i = 18 to i = 17, ΔR = [ 0.99566 -0.0018  -0.00215  0.09305], ΔT = [ 0.00255 -0.0329   0.99946]\n",
      "From i = 19 to i = 18, 65 keypoints were detected in the (i+1)th image, and 63 keypoints were detected in the ith image.\n",
      "From i = 19 to i = 18, ΔR = [ 0.99841 -0.00051  0.00032 -0.05634], ΔT = [-0.00861 -0.00087 -0.99996]\n",
      "From i = 20 to i = 19, 65 keypoints were detected in the (i+1)th image, and 65 keypoints were detected in the ith image.\n",
      "From i = 20 to i = 19, ΔR = [ 0.99964  0.00553  0.00337 -0.02592], ΔT = [-0.00471 -0.00665 -0.99997]\n",
      "From i = 21 to i = 20, 82 keypoints were detected in the (i+1)th image, and 65 keypoints were detected in the ith image.\n",
      "From i = 21 to i = 20, ΔR = [ 0.99912  0.00014 -0.00069 -0.04193], ΔT = [ 0.00855  0.01352  0.99987]\n",
      "From i = 22 to i = 21, 74 keypoints were detected in the (i+1)th image, and 82 keypoints were detected in the ith image.\n",
      "From i = 22 to i = 21, ΔR = [ 0.99986 -0.00052  0.0004  -0.01664], ΔT = [-0.00077 -0.01014  0.99995]\n",
      "From i = 23 to i = 22, 45 keypoints were detected in the (i+1)th image, and 74 keypoints were detected in the ith image.\n",
      "From i = 23 to i = 22, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 23 to i = 22, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 24 to i = 23, 61 keypoints were detected in the (i+1)th image, and 45 keypoints were detected in the ith image.\n",
      "From i = 24 to i = 23, ΔR = [ 0.99849 -0.00159 -0.00009 -0.0549 ], ΔT = [-0.00042  0.00444 -0.99999]\n",
      "From i = 25 to i = 24, 53 keypoints were detected in the (i+1)th image, and 61 keypoints were detected in the ith image.\n",
      "From i = 25 to i = 24, ΔR = [ 0.99875  0.00592  0.00699 -0.04914], ΔT = [ 0.02993  0.00568  0.99954]\n",
      "From i = 26 to i = 25, 61 keypoints were detected in the (i+1)th image, and 53 keypoints were detected in the ith image.\n",
      "From i = 26 to i = 25, ΔR = [ 0.99735 -0.00307 -0.00222 -0.07263], ΔT = [-0.02238  0.01342  0.99966]\n",
      "From i = 27 to i = 26, 56 keypoints were detected in the (i+1)th image, and 61 keypoints were detected in the ith image.\n",
      "From i = 27 to i = 26, ΔR = [ 0.99612 -0.01452  0.03064  0.0812 ], ΔT = [-0.30042 -0.00399  0.9538 ]\n",
      "From i = 28 to i = 27, 56 keypoints were detected in the (i+1)th image, and 56 keypoints were detected in the ith image.\n",
      "From i = 28 to i = 27, ΔR = [ 0.99773 -0.00501 -0.00764 -0.06667], ΔT = [ 0.00385 -0.01342 -0.9999 ]\n",
      "From i = 29 to i = 28, 51 keypoints were detected in the (i+1)th image, and 56 keypoints were detected in the ith image.\n",
      "From i = 29 to i = 28, ΔR = [ 0.99984  0.00034  0.00398  0.01764], ΔT = [ 0.02788 -0.00013  0.99961]\n",
      "From i = 30 to i = 29, 72 keypoints were detected in the (i+1)th image, and 51 keypoints were detected in the ith image.\n",
      "From i = 30 to i = 29, ΔR = [ 0.99796  0.00458  0.00496 -0.06342], ΔT = [ 0.05092  0.00273 -0.9987 ]\n",
      "From i = 31 to i = 30, 78 keypoints were detected in the (i+1)th image, and 72 keypoints were detected in the ith image.\n",
      "From i = 31 to i = 30, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 31 to i = 30, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 32 to i = 31, 39 keypoints were detected in the (i+1)th image, and 78 keypoints were detected in the ith image.\n",
      "From i = 32 to i = 31, ΔR = [ 0.12764  0.94248 -0.30866  0.01288], ΔT = [ 0.00271  0.19212  0.98137]\n",
      "From i = 33 to i = 32, 45 keypoints were detected in the (i+1)th image, and 39 keypoints were detected in the ith image.\n",
      "From i = 33 to i = 32, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 33 to i = 32, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 34 to i = 33, 49 keypoints were detected in the (i+1)th image, and 45 keypoints were detected in the ith image.\n",
      "From i = 34 to i = 33, no matches were found, so the origins of both images are treated as corresponding points.\n",
      "From i = 34 to i = 33, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 34 to i = 33, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 35 to i = 34, 46 keypoints were detected in the (i+1)th image, and 49 keypoints were detected in the ith image.\n",
      "From i = 35 to i = 34, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 35 to i = 34, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 36 to i = 35, 67 keypoints were detected in the (i+1)th image, and 46 keypoints were detected in the ith image.\n",
      "From i = 36 to i = 35, ΔR = [ 0.99592  0.00324  0.00203  0.09014], ΔT = [ 0.02016  0.00994 -0.99975]\n",
      "From i = 37 to i = 36, 56 keypoints were detected in the (i+1)th image, and 67 keypoints were detected in the ith image.\n",
      "From i = 37 to i = 36, ΔR = [-0.08981  0.84058 -0.53412  0.0093 ], ΔT = [-0.07972 -0.06662  0.99459]\n",
      "From i = 38 to i = 37, 45 keypoints were detected in the (i+1)th image, and 56 keypoints were detected in the ith image.\n",
      "From i = 38 to i = 37, ΔR = [ 0.9997   0.00244  0.00004  0.02417], ΔT = [-0.01573 -0.00046 -0.99988]\n",
      "From i = 39 to i = 38, 32 keypoints were detected in the (i+1)th image, and 45 keypoints were detected in the ith image.\n",
      "From i = 39 to i = 38, ΔR = [ 0.9991  -0.00118  0.00374  0.04213], ΔT = [ 0.00631  0.01113  0.99992]\n",
      "From i = 40 to i = 39, 56 keypoints were detected in the (i+1)th image, and 32 keypoints were detected in the ith image.\n",
      "From i = 40 to i = 39, ΔR = [ 0.00078  0.72679  0.68682 -0.00725], ΔT = [ 0.01154  0.01121  0.99987]\n",
      "From i = 41 to i = 40, 46 keypoints were detected in the (i+1)th image, and 56 keypoints were detected in the ith image.\n",
      "From i = 41 to i = 40, ΔR = [ 0.99963  0.00206 -0.00031 -0.02703], ΔT = [-0.00175 -0.00029  1.     ]\n",
      "From i = 42 to i = 41, 49 keypoints were detected in the (i+1)th image, and 46 keypoints were detected in the ith image.\n",
      "From i = 42 to i = 41, ΔR = [ 0.06289  0.44032  0.89562 -0.00408], ΔT = [-0.06143  0.02678  0.99775]\n",
      "From i = 43 to i = 42, 46 keypoints were detected in the (i+1)th image, and 49 keypoints were detected in the ith image.\n",
      "From i = 43 to i = 42, ΔR = [ 0.99163  0.00167  0.00352 -0.12905], ΔT = [-0.00659  0.00952  0.99993]\n",
      "From i = 44 to i = 43, 43 keypoints were detected in the (i+1)th image, and 46 keypoints were detected in the ith image.\n",
      "From i = 44 to i = 43, ΔR = [ 0.99992  0.00392  0.00174 -0.01218], ΔT = [-0.01853  0.01012  0.99978]\n",
      "From i = 45 to i = 44, 41 keypoints were detected in the (i+1)th image, and 43 keypoints were detected in the ith image.\n",
      "From i = 45 to i = 44, ΔR = [ 0.99924 -0.00358 -0.00702 -0.03808], ΔT = [ 0.00195  0.00814  0.99996]\n",
      "From i = 46 to i = 45, 39 keypoints were detected in the (i+1)th image, and 41 keypoints were detected in the ith image.\n",
      "From i = 46 to i = 45, ΔR = [ 0.99963  0.00475  0.00297 -0.0265 ], ΔT = [ 0.00617 -0.00366  0.99997]\n",
      "From i = 47 to i = 46, 31 keypoints were detected in the (i+1)th image, and 39 keypoints were detected in the ith image.\n",
      "From i = 47 to i = 46, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 47 to i = 46, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 48 to i = 47, 29 keypoints were detected in the (i+1)th image, and 31 keypoints were detected in the ith image.\n",
      "From i = 48 to i = 47, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 48 to i = 47, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 49 to i = 48, 30 keypoints were detected in the (i+1)th image, and 29 keypoints were detected in the ith image.\n",
      "From i = 49 to i = 48, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 49 to i = 48, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 50 to i = 49, 27 keypoints were detected in the (i+1)th image, and 30 keypoints were detected in the ith image.\n",
      "From i = 50 to i = 49, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 50 to i = 49, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 51 to i = 50, 31 keypoints were detected in the (i+1)th image, and 27 keypoints were detected in the ith image.\n",
      "From i = 51 to i = 50, ΔR = [ 0.07724  0.6744   0.73426  0.00909], ΔT = [-0.08567  0.07008  0.99386]\n",
      "From i = 52 to i = 51, 24 keypoints were detected in the (i+1)th image, and 31 keypoints were detected in the ith image.\n",
      "From i = 52 to i = 51, ΔR = [ 0.99997  0.00118 -0.00694  0.00328], ΔT = [ 0.00224  0.00381 -0.99999]\n",
      "From i = 53 to i = 52, 37 keypoints were detected in the (i+1)th image, and 24 keypoints were detected in the ith image.\n",
      "From i = 53 to i = 52, ΔR = [ 0.05065  0.73371  0.67752 -0.00836], ΔT = [-0.02937  0.04281  0.99865]\n",
      "From i = 54 to i = 53, 36 keypoints were detected in the (i+1)th image, and 37 keypoints were detected in the ith image.\n",
      "From i = 54 to i = 53, ΔR = [ 0.99983  0.00304  0.00851 -0.01628], ΔT = [ 0.01635 -0.00238  0.99986]\n",
      "From i = 55 to i = 54, 27 keypoints were detected in the (i+1)th image, and 36 keypoints were detected in the ith image.\n",
      "From i = 55 to i = 54, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 55 to i = 54, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 56 to i = 55, 41 keypoints were detected in the (i+1)th image, and 27 keypoints were detected in the ith image.\n",
      "From i = 56 to i = 55, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 56 to i = 55, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 57 to i = 56, 50 keypoints were detected in the (i+1)th image, and 41 keypoints were detected in the ith image.\n",
      "From i = 57 to i = 56, ΔR = [ 0.99838  0.00127 -0.00217 -0.05685], ΔT = [ 0.00932  0.00851 -0.99992]\n",
      "From i = 58 to i = 57, 39 keypoints were detected in the (i+1)th image, and 50 keypoints were detected in the ith image.\n",
      "From i = 58 to i = 57, ΔR = [ 0.98613 -0.00236  0.00242  0.16596], ΔT = [ 0.01051  0.007   -0.99992]\n",
      "From i = 59 to i = 58, 51 keypoints were detected in the (i+1)th image, and 39 keypoints were detected in the ith image.\n",
      "From i = 59 to i = 58, ΔR = [ 0.9987  -0.00153 -0.0083   0.05027], ΔT = [-0.00723 -0.00743  0.99995]\n",
      "From i = 60 to i = 59, 34 keypoints were detected in the (i+1)th image, and 51 keypoints were detected in the ith image.\n",
      "From i = 60 to i = 59, ΔR = [ 0.99692  0.0009   0.00745  0.07809], ΔT = [ 0.02213 -0.00089  0.99975]\n",
      "From i = 61 to i = 60, 49 keypoints were detected in the (i+1)th image, and 34 keypoints were detected in the ith image.\n",
      "From i = 61 to i = 60, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 61 to i = 60, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 62 to i = 61, 60 keypoints were detected in the (i+1)th image, and 49 keypoints were detected in the ith image.\n",
      "From i = 62 to i = 61, ΔR = [ 0.99986  0.00042 -0.00566  0.01564], ΔT = [ 0.00071  0.00227  1.     ]\n",
      "From i = 63 to i = 62, 46 keypoints were detected in the (i+1)th image, and 60 keypoints were detected in the ith image.\n",
      "From i = 63 to i = 62, ΔR = [ 0.98753 -0.00549  0.00793  0.15711], ΔT = [ 0.01116 -0.00208  0.99994]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m99\u001b[39m):\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m###################################\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Note that we are using the (i+1)th image as the \"before\" image and the ith image as the \"after \"image\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# because we are required to calculate the transformation required to return to the (i+1)th image.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     sift \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mSIFT_create()\n\u001b[0;32m---> 32\u001b[0m     kp1, des1 \u001b[38;5;241m=\u001b[39m \u001b[43msift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectAndCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     kp2, des2 \u001b[38;5;241m=\u001b[39m sift\u001b[38;5;241m.\u001b[39mdetectAndCompute(images[i], \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Print the number of keypoints detected.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The camera intrinsic matrix K is given.\n",
    "# This describes the focal length, optical center, and skew of the camera.\n",
    "# Source: https://www.drivendata.org/competitions/261/spacecraft-pose-estimation/page/834/#camera-intrinsic-parameters\n",
    "K = np.array([[5.2125371e+03, 0.0000000e+00, 6.4000000e+02],\n",
    "              [0.0000000e+00, 6.2550444e+03, 5.1200000e+02],\n",
    "              [0.0000000e+00, 0.0000000e+00, 1.0000000e+00]])\n",
    "\n",
    "# As i increases from 0 to 98, the overall transformation which brings image i back to image 0 is calculated.\n",
    "returning_rotation = np.array([1, 0, 0, 0])\n",
    "returning_translation = np.array([0, 0, 0])\n",
    "\n",
    "PATH_TO_RESULTS_FILE = \"results.csv\"\n",
    "PATH_TO_INCREMENTAL_RESULTS_FILE = \"nn_X.csv\"\n",
    "\n",
    "with open(PATH_TO_RESULTS_FILE, \"w\") as f, open(PATH_TO_INCREMENTAL_RESULTS_FILE, \"w\") as f2:\n",
    "    f.write(\"chain_id,i,x,y,z,qw,qx,qy,qz\\n\")\n",
    "    f.write(f\"{CHAIN_ID},0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\\n\")\n",
    "    f2.write(\"chain_id,i,x,y,z,qw,qx,qy,qz\\n\")\n",
    "    f2.write(f\"{CHAIN_ID},0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\\n\")\n",
    "\n",
    "    # For each pair of images (i, i+1),...\n",
    "    for i in range(0, 99):\n",
    "\n",
    "        ###################################\n",
    "        # FEATURE DETECTION AND MATCHING  #\n",
    "        ###################################\n",
    "\n",
    "        # Create an SIFT object and use it to detect key points and descriptors.\n",
    "        # Note that we are using the (i+1)th image as the \"before\" image and the ith image as the \"after \"image\n",
    "        # because we are required to calculate the transformation required to return to the (i+1)th image.\n",
    "        sift = cv.SIFT_create()\n",
    "        kp1, des1 = sift.detectAndCompute(images[i+1], None)\n",
    "        kp2, des2 = sift.detectAndCompute(images[i], None)\n",
    "\n",
    "        # Print the number of keypoints detected.\n",
    "        print(f\"From i = {i+1:02} to i = {i:02}, {len(kp1)} keypoints were detected in the (i+1)th image, and {len(kp2)} keypoints were detected in the ith image.\")\n",
    "\n",
    "        # Create a BFMatcher object.\n",
    "        bf = cv.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply the ratio test to obtain unambiguous (good) matches.\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "        # Draw the matches.\n",
    "        img_matches = cv.drawMatches(images[i+1], kp1, images[i], kp2, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "        # Save the matches in a folder.\n",
    "        # Create a folder to save the matches if it doesn't already exist.\n",
    "        if not os.path.exists(\"results\"):\n",
    "            os.makedirs(\"results\")\n",
    "        cv.imwrite(\"results/matches_{:03d}_{:03d}.png\".format(i, i+1), img_matches)\n",
    "\n",
    "        ###################################\n",
    "        # TRANSFORMATION CALCULATION      #\n",
    "        ###################################\n",
    "\n",
    "        # Extract the matched keypoints.\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # (If there are no matches, add a row of zeros to src_pts and dst_pts to prevent errors later on.)\n",
    "        if len(src_pts) == 0:\n",
    "            print(f\"From i = {i+1:02} to i = {i:02}, no matches were found, so the origins of both images are treated as corresponding points.\")\n",
    "            src_pts = np.zeros((1, 1, 2))\n",
    "            dst_pts = np.zeros((1, 1, 2))\n",
    "\n",
    "        # Extract the fundamental matrix, which describes the relative motion between two camera angles.\n",
    "        F, mask = cv.findFundamentalMat(src_pts, dst_pts, cv.FM_RANSAC)\n",
    "\n",
    "        # (Sometimes, the fundamental matrix cannot be found. F will be None, which causes errors later on.)\n",
    "        if F is None:\n",
    "            print(f\"From i = {i+1:02} to i = {i:02}, F could not be calculated, so F was set as the identity matrix.\")\n",
    "            F = np.eye(3)\n",
    "\n",
    "        # (When there are seven matches, cv.findFundamentalMat() returns three solutions as a matrix of shape (9, 3).\n",
    "        # We arbitrarily choose the first solution.)\n",
    "        if F.shape == (9, 3):\n",
    "            F = F[:3]\n",
    "\n",
    "        # Adjust for the effects of the camera's distortion on the image.\n",
    "        E = K.T @ F @ K\n",
    "\n",
    "        # Extract the rotation matrix R and translation T.\n",
    "        _, R, T, mask = cv.recoverPose(E, src_pts, dst_pts, K)\n",
    "        T = T.flatten() # Change the shape of T from (3, 1) to (3,)\n",
    "\n",
    "        # Convert the rotation matrix to a quaternion.\n",
    "        r = Rotation.from_matrix(R)\n",
    "        q_xyzw = r.as_quat()\n",
    "        q_wxyz = np.roll(q_xyzw, 1)\n",
    "\n",
    "        # Write the results to the CSV file for the neural network's training.\n",
    "        f2.write(f\"{CHAIN_ID},{i+1},{T[0]},{T[1]},{T[2]},{q_wxyz[0]},{q_wxyz[1]},{q_wxyz[2]},{q_wxyz[3]}\\n\")\n",
    "\n",
    "        # Print the results.\n",
    "        # (Turn off scientific notation. Five decimal places. Always leave a space before the ' ' for the sign.)\n",
    "        np.set_printoptions(suppress=True, precision=5, sign=' ')\n",
    "        print(f\"From i = {i+1:02} to i = {i:02}, ΔR = {q_wxyz}, ΔT = {T}\")\n",
    "\n",
    "        # Write the results to the CSV file.\n",
    "        returning_rotation, returning_translation = compose_transformations(q_wxyz, T, returning_rotation, returning_translation) \n",
    "        f.write(f\"{CHAIN_ID},{i+1},{returning_translation[0]},{returning_translation[1]},{returning_translation[2]},{returning_rotation[0]},{returning_rotation[1]},{returning_rotation[2]},{returning_rotation[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
