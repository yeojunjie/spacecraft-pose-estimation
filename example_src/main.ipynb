{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Enhancement of ORB/RANSAC Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import * # ⚠️⚠️ The functions in utils.py are not correct.\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation # If the module is not found, run `pip install scipy` in this .ipynb in a separate code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Training Labels\n",
    "\n",
    "### Conversion of Net Transformation to Incremental Transformations\n",
    "⚠️⚠️ The conversion is not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data, which contains net transformations.\n",
    "PATH_TO_INPUT_FILE = \"train_labels_one_chain_only.csv\"\n",
    "PATH_TO_OUTPUT_FILE = \"nn_Y.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH_TO_INPUT_FILE)\n",
    "\n",
    "# Create a new CSV file.\n",
    "with open(PATH_TO_OUTPUT_FILE, \"w\") as f:\n",
    "\n",
    "    # Write the first row of data in df to the new CSV file.\n",
    "    df.iloc[[0]].to_csv(f, index=False)\n",
    "\n",
    "    # Iterate through the rows of the dataframe, and calculate the incremental transformations.\n",
    "    for i in range(1, 100):\n",
    "        # Analogy: When i = 5, we wish to calculate the transformation which brings image 5 to image 4.\n",
    "        # 05 -> 04 can be calculated by applying 05 -> 00, then 00 -> 04.\n",
    "\n",
    "        curr_transformation_row = df.iloc[i]   # 05 -> 00\n",
    "        prev_transformation_row = df.iloc[i-1] # 04 -> 00\n",
    "\n",
    "        chain_id = curr_transformation_row[\"chain_id\"]\n",
    "\n",
    "        curr_R = np.array([curr_transformation_row[\"qw\"], curr_transformation_row[\"qx\"], curr_transformation_row[\"qy\"], curr_transformation_row[\"qz\"]])\n",
    "        curr_T = np.array([curr_transformation_row[\"x\"], curr_transformation_row[\"y\"], curr_transformation_row[\"z\"]])\n",
    "\n",
    "        prev_R = np.array([prev_transformation_row[\"qw\"], prev_transformation_row[\"qx\"], prev_transformation_row[\"qy\"], prev_transformation_row[\"qz\"]])\n",
    "        prev_T = np.array([prev_transformation_row[\"x\"], prev_transformation_row[\"y\"], prev_transformation_row[\"z\"]])\n",
    "\n",
    "        # Calculate 00 -> 04.\n",
    "        inv_prev_R, inv_prev_T = calculate_inverse_transformation(prev_R, prev_T)\n",
    "\n",
    "        # Calculate 05 -> 04.\n",
    "        R_incremental, T_incremental = compose_transformations(curr_R, curr_T, inv_prev_R, inv_prev_T)\n",
    "\n",
    "        # Write the incremental transformations to the new CSV file.\n",
    "        f.write(f\"{chain_id},{i},{T_incremental[0]},{T_incremental[1]},{T_incremental[2]},{R_incremental[0]},{R_incremental[1]},{R_incremental[2]},{R_incremental[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Sanity Check) Conversion Back to Net Transformations\n",
    "Hopefully, the file we generate `PATH_TO_SANITY_CHECK_FILE` has similar transformations as the `PATH_TO_INPUT_FILE`.\n",
    "\n",
    "Currently, the rotational components are reverse-engineered from the net transformations correctly! 🎉\n",
    "\n",
    "However, the translational components are not. 🫤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SANITY_CHECK_FILE = \"train_labels_sanity_check.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH_TO_OUTPUT_FILE)\n",
    "\n",
    "# Create a new CSV file.\n",
    "with open(PATH_TO_SANITY_CHECK_FILE, \"w\") as f:\n",
    "\n",
    "    # Write the first row of data in df to the new CSV file.\n",
    "    df.iloc[[0]].to_csv(f, index=False)\n",
    "\n",
    "    # Iterate through the rows of the dataframe, and calculate the net transformation.\n",
    "    T_net = np.zeros((3))\n",
    "    R_net = np.array([1, 0, 0, 0])\n",
    "\n",
    "    for i in range(1, 100):\n",
    "        curr_row = df.iloc[i]\n",
    "        chain_id = curr_row[\"chain_id\"]\n",
    "\n",
    "        T_incremental = np.array([curr_row[\"x\"], curr_row[\"y\"], curr_row[\"z\"]])\n",
    "        R_incremental = np.array([curr_row[\"qw\"], curr_row[\"qx\"], curr_row[\"qy\"], curr_row[\"qz\"]])\n",
    "\n",
    "        R_net, T_net = compose_transformations(R_incremental, T_incremental, R_net, T_net)\n",
    "\n",
    "        # Write the net transformations to the new CSV file.\n",
    "        f.write(f\"{chain_id},{i},{T_net[0]},{T_net[1]},{T_net[2]},{R_net[0]},{R_net[1]},{R_net[2]},{R_net[3]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ORB, BFMatcher, RANSAC to Compute Transformations\n",
    "ORB (Oriented FAST and Rotated BRIEF) detects features.\n",
    "\n",
    "BFMatcher (Brute-Force Matcher) matches features between two images.\n",
    "\n",
    "RANSAC (RANdom SAmple Consensus) estimates the transformation between two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAIN_ID = '0a998b28bd'\n",
    "ABSOLUTE_PATH_TO_FOLDER = os.path.abspath(os.path.join('..', 'data', 'images', CHAIN_ID))\n",
    "\n",
    "images = []\n",
    "for i in range(0, 100):\n",
    "    PATH_TO_IMAGE = os.path.join(ABSOLUTE_PATH_TO_FOLDER, f\"{i:03}\" + \".png\")\n",
    "    img = cv.imread(PATH_TO_IMAGE)\n",
    "    images.append(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Transformations\n",
    "The between-image transformations are computed.\n",
    "\n",
    "We wish to throw these into a neural network to adjust their values, especially for the translational components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From i = 01 to i = 00, ΔR = [ 0.99366  0.00085  0.01564  0.11136], ΔT = [-0.03038  0.00004 -0.99954]\n",
      "From i = 02 to i = 01, ΔR = [ 0.98798  0.06133 -0.09128  0.10867], ΔT = [ 0.36538  0.49945 -0.78552]\n",
      "From i = 03 to i = 02, ΔR = [ 0.9989  -0.00261 -0.00469  0.04666], ΔT = [ 0.02803 -0.00023 -0.99961]\n",
      "From i = 04 to i = 03, ΔR = [ 0.99945 -0.00366  0.01256  0.03062], ΔT = [ 0.03634 -0.01315 -0.99925]\n",
      "From i = 05 to i = 04, ΔR = [-0.24371  0.84636 -0.46641 -0.08216], ΔT = [-0.08992 -0.03841  0.99521]\n",
      "From i = 06 to i = 05, ΔR = [ 0.99947  0.00133 -0.00717  0.03166], ΔT = [-0.01786 -0.02004  0.99964]\n",
      "From i = 07 to i = 06, ΔR = [ 0.99878 -0.00321  0.00684 -0.04872], ΔT = [ 0.00645  0.00563  0.99996]\n",
      "From i = 08 to i = 07, ΔR = [ 0.23337 -0.52451  0.81868 -0.01411], ΔT = [-0.27094 -0.0724   0.95987]\n",
      "From i = 09 to i = 08, ΔR = [ 0.99991  0.00136  0.00605 -0.01225], ΔT = [-0.00933 -0.00263 -0.99995]\n",
      "From i = 10 to i = 09, ΔR = [ 0.99971  0.00222 -0.00485 -0.02328], ΔT = [ 0.0043   0.01253 -0.99991]\n",
      "From i = 11 to i = 10, ΔR = [ 0.34686  0.40048  0.84326 -0.09067], ΔT = [-0.39705  0.44433  0.80307]\n",
      "From i = 12 to i = 11, ΔR = [ 0.99339  0.03629 -0.00638 -0.10871], ΔT = [ 0.06081  0.11319 -0.99171]\n",
      "From i = 13 to i = 12, ΔR = [ 0.99893  0.0079  -0.00367 -0.04542], ΔT = [-0.00962 -0.00695  0.99993]\n",
      "From i = 14 to i = 13, ΔR = [ 0.99957  0.00243 -0.0031  -0.0289 ], ΔT = [-0.00442  0.00137  0.99999]\n",
      "From i = 15 to i = 14, ΔR = [ 0.99992 -0.00706  0.00314 -0.00987], ΔT = [-0.00713 -0.01374 -0.99988]\n",
      "From i = 16 to i = 15, ΔR = [ 0.99996 -0.00015 -0.00075 -0.00838], ΔT = [-0.00334  0.00075 -0.99999]\n",
      "From i = 17 to i = 16, ΔR = [ 0.87428  0.00523 -0.02864 -0.48454], ΔT = [ 0.00628  0.009    0.99994]\n",
      "From i = 18 to i = 17, ΔR = [ 0.98241 -0.00972  0.00494  0.18641], ΔT = [ 0.00258  0.01211  0.99992]\n",
      "From i = 19 to i = 18, ΔR = [ 0.99957  0.00744 -0.00042 -0.02828], ΔT = [-0.0009   0.0093  -0.99996]\n",
      "From i = 20 to i = 19, ΔR = [ 0.7401   0.66039 -0.12002 -0.04163], ΔT = [ 0.68586  0.54693  0.48006]\n",
      "From i = 21 to i = 20, ΔR = [ 0.98859  0.01456 -0.00492  0.14986], ΔT = [ 0.02916  0.02163  0.99934]\n",
      "From i = 22 to i = 21, ΔR = [ 0.96595 -0.2026   0.1014   0.12494], ΔT = [-0.07475 -0.09619  0.99255]\n",
      "From i = 23 to i = 22, ΔR = [ 0.99998 -0.00263  0.00237 -0.00557], ΔT = [ 0.01324  0.01919 -0.99973]\n",
      "From i = 24 to i = 23, ΔR = [ 0.99728  0.00963 -0.00722 -0.07278], ΔT = [-0.02407 -0.03115  0.99922]\n",
      "From i = 25 to i = 24, ΔR = [ 0.99991  0.00243  0.00185 -0.01337], ΔT = [-0.00167  0.0011  -1.     ]\n",
      "From i = 26 to i = 25, ΔR = [ 0.84537  0.01776  0.02358  0.53337], ΔT = [-0.00642  0.01444  0.99988]\n",
      "From i = 27 to i = 26, ΔR = [ 0.80908  0.0938  -0.20644  0.54219], ΔT = [ 0.07583 -0.40614  0.91066]\n",
      "From i = 28 to i = 27, ΔR = [ 0.99817 -0.00088 -0.00035  0.06051], ΔT = [ 0.0055  -0.02093 -0.99977]\n",
      "From i = 29 to i = 28, ΔR = [ 0.94157 -0.01935 -0.16551  0.29269], ΔT = [-0.05067  0.38827 -0.92015]\n",
      "From i = 30 to i = 29, ΔR = [ 0.99892 -0.00103 -0.00429 -0.04627], ΔT = [-0.00786  0.03314  0.99942]\n",
      "From i = 31 to i = 30, ΔR = [ 0.54075  0.45432  0.7029   0.08429], ΔT = [-0.09192  0.46529  0.88037]\n",
      "From i = 32 to i = 31, ΔR = [ 0.9988   0.00628  0.00347 -0.04846], ΔT = [ 0.00802 -0.0317  -0.99947]\n",
      "From i = 33 to i = 32, ΔR = [ 0.99946  0.0158   0.02849 -0.00435], ΔT = [-0.22089  0.03282  0.97475]\n",
      "From i = 34 to i = 33, ΔR = [ 0.99941 -0.00739 -0.00302  0.03336], ΔT = [-0.0072   0.02959  0.99954]\n",
      "From i = 35 to i = 34, ΔR = [ 0.9974  -0.0138  -0.02119 -0.06747], ΔT = [ 0.04603  0.01649  0.9988 ]\n",
      "From i = 36 to i = 35, ΔR = [-0.55311  0.2501   0.78568  0.11929], ΔT = [ 0.28647 -0.73194  0.61822]\n",
      "From i = 37 to i = 36, ΔR = [ 0.8948   0.19126 -0.17703  0.36251], ΔT = [-0.31169  0.52581 -0.79144]\n",
      "From i = 38 to i = 37, ΔR = [ 0.99691 -0.01602 -0.01198 -0.07601], ΔT = [ 0.00973 -0.01888 -0.99977]\n",
      "From i = 39 to i = 38, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 39 to i = 38, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 40 to i = 39, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 40 to i = 39, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 41 to i = 40, F could not be calculated, so F was set as the identity matrix.\n",
      "From i = 41 to i = 40, ΔR = [ 0.70711  0.08589  0.05726 -0.69953], ΔT = [-0.12147 -0.08098  0.98929]\n",
      "From i = 42 to i = 41, F could not be calculated, so F was set as the identity matrix.\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/calib3d/src/five-point.cpp:572: error: (-215:Assertion failed) npoints >= 0 && points2.checkVector(2) == npoints && points1.type() == points2.type() in function 'recoverPose'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m E \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m F \u001b[38;5;241m@\u001b[39m K\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Extract the rotation matrix R and translation T.\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m _, R, T, mask \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecoverPose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_pts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m T \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;66;03m# Change the shape of T from (3, 1) to (3,)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Convert the rotation matrix to a quaternion.\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/calib3d/src/five-point.cpp:572: error: (-215:Assertion failed) npoints >= 0 && points2.checkVector(2) == npoints && points1.type() == points2.type() in function 'recoverPose'\n"
     ]
    }
   ],
   "source": [
    "# The camera intrinsic matrix K is given.\n",
    "# This describes the focal length, optical center, and skew of the camera.\n",
    "# Source: https://www.drivendata.org/competitions/261/spacecraft-pose-estimation/page/834/#camera-intrinsic-parameters\n",
    "K = np.array([[5.2125371e+03, 0.0000000e+00, 6.4000000e+02],\n",
    "              [0.0000000e+00, 6.2550444e+03, 5.1200000e+02],\n",
    "              [0.0000000e+00, 0.0000000e+00, 1.0000000e+00]])\n",
    "\n",
    "# As i increases from 0 to 98, the overall transformation which brings image i back to image 0 is calculated.\n",
    "returning_rotation = np.array([1, 0, 0, 0])\n",
    "returning_translation = np.array([0, 0, 0])\n",
    "\n",
    "PATH_TO_RESULTS_FILE = \"results.csv\"\n",
    "PATH_TO_INCREMENTAL_RESULTS_FILE = \"nn_X.csv\"\n",
    "\n",
    "with open(PATH_TO_RESULTS_FILE, \"w\") as f, open(PATH_TO_INCREMENTAL_RESULTS_FILE, \"w\") as f2:\n",
    "    f.write(\"chain_id,i,x,y,z,qw,qx,qy,qz\\n\")\n",
    "    f.write(f\"{CHAIN_ID},0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\\n\")\n",
    "    f2.write(\"chain_id,i,x,y,z,qw,qx,qy,qz\\n\")\n",
    "    f2.write(f\"{CHAIN_ID},0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\\n\")\n",
    "\n",
    "    # For each pair of images (i, i+1),...\n",
    "    for i in range(0, 99):\n",
    "\n",
    "        ###################################\n",
    "        # FEATURE DETECTION AND MATCHING  #\n",
    "        ###################################\n",
    "\n",
    "        # Create an SIFT object and use it to detect key points and descriptors.\n",
    "        # Note that we are using the (i+1)th image as the \"before\" image and the ith image as the \"after \"image\n",
    "        # because we are required to calculate the transformation required to return to the (i+1)th image.\n",
    "        sift = cv.SIFT_create()\n",
    "        kp1, des1 = sift.detectAndCompute(images[i+1], None)\n",
    "        kp2, des2 = sift.detectAndCompute(images[i], None)\n",
    "\n",
    "        # Create a BFMatcher object.\n",
    "        bf = cv.BFMatcher()\n",
    "        matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Apply the ratio test to obtain unambiguous (good) matches.\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.75 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "        # Draw the matches.\n",
    "        img_matches = cv.drawMatches(images[i+1], kp1, images[i], kp2, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "        # Save the matches in a folder.\n",
    "        # Create a folder to save the matches if it doesn't already exist.\n",
    "        # if not os.path.exists(\"results\"):\n",
    "        #     os.makedirs(\"results\")\n",
    "        # cv.imwrite(\"results/matches_{:03d}_{:03d}.png\".format(i, i+1), img_matches)\n",
    "\n",
    "        ###################################\n",
    "        # TRANSFORMATION CALCULATION      #\n",
    "        ###################################\n",
    "\n",
    "        # Extract the matched keypoints.\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Extract the fundamental matrix, which describes the relative motion between two camera angles.\n",
    "        F, mask = cv.findFundamentalMat(src_pts, dst_pts, cv.FM_RANSAC)\n",
    "\n",
    "        # (Sometimes, the fundamental matrix cannot be found. F will be None, which causes errors later on.)\n",
    "        if F is None:\n",
    "            print(f\"From i = {i+1:02} to i = {i:02}, F could not be calculated, so F was set as the identity matrix.\")\n",
    "            F = np.eye(3)\n",
    "\n",
    "        # (When there are seven matches, cv.findFundamentalMat() returns three solutions as a matrix of shape (9, 3).\n",
    "        # We arbitrarily choose the first solution.)\n",
    "        if F.shape == (9, 3):\n",
    "            F = F[:3]\n",
    "\n",
    "        # Adjust for the effects of the camera's distortion on the image.\n",
    "        E = K.T @ F @ K\n",
    "\n",
    "        # Extract the rotation matrix R and translation T.\n",
    "        _, R, T, mask = cv.recoverPose(E, src_pts, dst_pts, K)\n",
    "        T = T.flatten() # Change the shape of T from (3, 1) to (3,)\n",
    "\n",
    "        # Convert the rotation matrix to a quaternion.\n",
    "        r = Rotation.from_matrix(R)\n",
    "        q_xyzw = r.as_quat()\n",
    "        q_wxyz = np.roll(q_xyzw, 1)\n",
    "\n",
    "        # Write the results to the CSV file for the neural network's training.\n",
    "        f2.write(f\"{CHAIN_ID},{i+1},{T[0]},{T[1]},{T[2]},{q_wxyz[0]},{q_wxyz[1]},{q_wxyz[2]},{q_wxyz[3]}\\n\")\n",
    "\n",
    "        # Print the results.\n",
    "        # (Turn off scientific notation. Five decimal places. Always leave a space before the ' ' for the sign.)\n",
    "        np.set_printoptions(suppress=True, precision=5, sign=' ')\n",
    "        print(f\"From i = {i+1:02} to i = {i:02}, ΔR = {q_wxyz}, ΔT = {T}\")\n",
    "\n",
    "        # Write the results to the CSV file.\n",
    "        returning_rotation, returning_translation = compose_transformations(q_wxyz, T, returning_rotation, returning_translation) \n",
    "        f.write(f\"{CHAIN_ID},{i+1},{returning_translation[0]},{returning_translation[1]},{returning_translation[2]},{returning_rotation[0]},{returning_rotation[1]},{returning_rotation[2]},{returning_rotation[3]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
