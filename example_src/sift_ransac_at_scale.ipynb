{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "CHAIN_ID = \"0a998b28bd\"\n",
    "PATH_TO_FOLDER = \"/Users/yeojunjie/Documents/NUS Modules/CS3263/Project/spacecraft-pose-estimation/data/images/\" + CHAIN_ID + \"/\"\n",
    "\n",
    "# The camera intrinsic matrix.\n",
    "# Source: https://www.drivendata.org/competitions/261/spacecraft-pose-estimation/page/834/#camera-intrinsic-parameters\n",
    "K = np.array([[5.2125371e+03, 0.0000000e+00, 6.4000000e+02],\n",
    "              [0.0000000e+00, 6.2550444e+03, 5.1200000e+02],\n",
    "              [0.0000000e+00, 0.0000000e+00, 1.0000000e+00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a rotation matrix to a quaternion.\n",
    "# Source: https://en.wikipedia.org/wiki/Rotation_formalisms_in_three_dimensions#Rotation_matrix_â†”_quaternion\n",
    "def rotation_matrix_to_quaternion(R):\n",
    "    q = np.empty((4,))\n",
    "    q[0] = np.sqrt(1 + R[0, 0] + R[1, 1] + R[2, 2]) / 2\n",
    "    q[1] = (R[2, 1] - R[1, 2]) / (4 * q[0])\n",
    "    q[2] = (R[0, 2] - R[2, 0]) / (4 * q[0])\n",
    "    q[3] = (R[1, 0] - R[0, 1]) / (4 * q[0])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the translation vector and rotation quartenion between the i-th and the j-th image in the list.\n",
    "# (In our usage, i + 1 = j.)\n",
    "def get_translation_and_rotation(list, i, j):\n",
    "    assert i < len(list) and j < len(list)\n",
    "\n",
    "    # Convert the images to grayscale. (Why am I even doing this?)\n",
    "    gray_i = cv.cvtColor(list[i], cv.COLOR_BGR2GRAY)\n",
    "    gray_j = cv.cvtColor(list[j], cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the keypoints and descriptors with SIFT.\n",
    "    sift = cv.SIFT_create()\n",
    "    keypoints_i, descriptors_i = sift.detectAndCompute(gray_i, None)\n",
    "    keypoints_j, descriptors_j = sift.detectAndCompute(gray_j, None)\n",
    "\n",
    "    # Create a BFMatcher object and match the descriptors.\n",
    "    bf = cv.BFMatcher(cv.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(descriptors_i, descriptors_j)\n",
    "\n",
    "    # # Extract the good matches.\n",
    "    # good_matches = []\n",
    "    # for m, n in matches: # TODO: Find out why this is suggested.\n",
    "    #     if m.distance < 0.75 * n.distance:\n",
    "    #         good_matches.append(m)\n",
    "    \n",
    "    # Extract corresponding points.\n",
    "    points_i = np.float32([keypoints_i[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    points_j = np.float32([keypoints_j[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Find the fundamental matrix F.\n",
    "    F, mask = cv.findFundamentalMat(points_i, points_j, cv.FM_RANSAC, 0.1, 0.99)\n",
    "\n",
    "    # Really dodgy error handling: If F is None, make it an identity matrix.\n",
    "    if F is None:\n",
    "        F = np.eye(3)\n",
    "        \n",
    "    # Calculate the essential matrix E.\n",
    "    E = np.dot(np.dot(K.T, F), K)\n",
    "\n",
    "\n",
    "    # Decompose E to get the rotation matrix R and the translation matrix T.\n",
    "    _, R, T, mask = cv.recoverPose(E, points_i, points_j, K)\n",
    "\n",
    "    # Convert the rotation matrix to a quaternion.\n",
    "    R = rotation_matrix_to_quaternion(R)\n",
    "\n",
    "    return T, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose rotation matrices and translation vectors.\n",
    "def compose_rotation_and_translation(T1, R1, T2, R2):\n",
    "    # TODO: All this flip-flopping between quartenions and rotation matrices seems unnecessary.\n",
    "    \n",
    "    # Convert the quaternions to rotation matrices.\n",
    "    R1 = np.array([[1 - 2 * R1[2]**2 - 2 * R1[3]**2, 2 * R1[1] * R1[2] - 2 * R1[0] * R1[3], 2 * R1[0] * R1[2] + 2 * R1[1] * R1[3]],\n",
    "                   [2 * R1[1] * R1[2] + 2 * R1[0] * R1[3], 1 - 2 * R1[1]**2 - 2 * R1[3]**2, 2 * R1[2] * R1[3] - 2 * R1[0] * R1[1]],\n",
    "                   [2 * R1[1] * R1[3] - 2 * R1[0] * R1[2], 2 * R1[0] * R1[1] + 2 * R1[2] * R1[3], 1 - 2 * R1[1]**2 - 2 * R1[2]**2]])\n",
    "    \n",
    "    R2 = np.array([[1 - 2 * R2[2]**2 - 2 * R2[3]**2, 2 * R2[1] * R2[2] - 2 * R2[0] * R2[3], 2 * R2[0] * R2[2] + 2 * R2[1] * R2[3]],\n",
    "                   [2 * R2[1] * R2[2] + 2 * R2[0] * R2[3], 1 - 2 * R2[1]**2 - 2 * R2[3]**2, 2 * R2[2] * R2[3] - 2 * R2[0] * R2[1]],\n",
    "                   [2 * R2[1] * R2[3] - 2 * R2[0] * R2[2], 2 * R2[0] * R2[1] + 2 * R2[2] * R2[3], 1 - 2 * R2[1]**2 - 2 * R2[2]**2]])\n",
    "\n",
    "    # Compose the rotation matrices.\n",
    "    R = R2 @ R1\n",
    "\n",
    "    # Compose the translation vectors.\n",
    "    T = R2 @ T1.T + T2.T\n",
    "\n",
    "    # Convert the rotation matrix to a quaternion.\n",
    "    R = rotation_matrix_to_quaternion(R)\n",
    "\n",
    "    return T, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 100 images.\n",
    "images = []\n",
    "for i in range(0, 100):\n",
    "    PATH_TO_IMAGE = os.path.join(PATH_TO_FOLDER, \"{:03d}.png\".format(i))\n",
    "    image = cv.imread(PATH_TO_IMAGE)\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and report the results.\n",
    "\n",
    "# Create a .csv file with header \"chain_id,i,x,y,z,qw,qx,qy,qz\".\n",
    "with open(\"results.csv\", \"w\") as file:\n",
    "    file.write(\"chain_id,i,x,y,z,qw,qx,qy,qz\\n\")\n",
    "\n",
    "    # Initialize the translation vector and the rotation quaternion.\n",
    "    # These two variables will be updated as we iterate through the chain of 100 images.\n",
    "    T = np.zeros((3,))\n",
    "    R = np.array([1, 0, 0, 0])\n",
    "\n",
    "    # Write the line for i = 0.\n",
    "    file.write(CHAIN_ID + \",0,0.0,0.0,0.0,1.0,0.0,0.0,0.0\\n\")\n",
    "\n",
    "    # Iterate through the images.\n",
    "    for i in range(1, 100):\n",
    "        # Get the translation vector and the rotation quaternion.\n",
    "        T_i, R_i = get_translation_and_rotation(images, i - 1, i)\n",
    "\n",
    "        # Compose the translation vector and the rotation quaternion.\n",
    "        T, R = compose_rotation_and_translation(T, R, T_i, R_i)\n",
    "\n",
    "        # Write the results to the .csv file.\n",
    "        file.write(\"{},{},{},{},{},{},{},{},{}\\n\".format(CHAIN_ID, i, T[0][0], T[0][1], T[0][2], R[0], R[1], R[2], R[3]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
