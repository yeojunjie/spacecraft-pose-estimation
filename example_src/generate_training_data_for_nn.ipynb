{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Training Data for Neural Network\n",
    "\n",
    "This file generates `nn_X.csv` and `nn_Y.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from process_one_chain_using_sift_ransac import *\n",
    "\n",
    "NN_X_OUTPUT_FILE_NAME = \"nn_X.csv\"\n",
    "NN_Y_OUTPUT_FILE_NAME = \"nn_Y.csv\"\n",
    "ABSOLUTE_PATH_TO_IMAGES_FOLDER = os.path.join(\"../data/images\")\n",
    "ABSOLUTE_PATH_TO_RANGE_DATA = os.path.join(\"../data/range.csv\")\n",
    "ABSOLUTE_PATH_TO_GROUND_TRUTH = os.path.join(\"../data/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of `nn_X.csv`\n",
    "1. Iterate through some folders (image chains) in `data/images` and put them through the SIFT/RANSAC pipeline.\n",
    "2. Write the incremental transformations calculated in `nn_X.csv`.\n",
    "3. Read the corresponding values from `data/range.csv` and add them to `nn_X.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a CSV file and write the header.\n",
    "\n",
    "\n",
    "with open(NN_X_OUTPUT_FILE_NAME, \"w\") as file:\n",
    "    file.write(\"chain_id,i,range,x,y,z,qw,qx,qy,qz\\n\")\n",
    "\n",
    "# Load the data.\n",
    "chain_ids = os.listdir(ABSOLUTE_PATH_TO_IMAGES_FOLDER)\n",
    "if '.DS_Store' in chain_ids:\n",
    "    chain_ids.remove('.DS_Store') # This is a hidden folder.\n",
    "\n",
    "# Sort the chain IDs by alphebatical order.\n",
    "chain_ids.sort()\n",
    "\n",
    "for index, chain_id in enumerate(chain_ids[:5]):\n",
    "    print(f'Processing chain {index + 1} of 5...')\n",
    "    absolute_path_to_chain_folder = os.path.join(ABSOLUTE_PATH_TO_IMAGES_FOLDER, chain_id)\n",
    "    process_one_chain_using_sift_ransac(absolute_path_to_chain_folder, ABSOLUTE_PATH_TO_RANGE_DATA, NN_X_OUTPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of `nn_Y.csv`\n",
    "1. For each image chain that was processed when generating `nn_X.csv`, calculate the incremental transformations using `data/train_labels.csv`.\n",
    "2. Write the incremental transformations to `nn_Y.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0036465cc6', '0053053e5a', '009ac5e872', '00f87cb03e', '0165a57d79']\n",
      "Processing chain 1 of 5...\n",
      "Processing chain 2 of 5...\n",
      "Processing chain 3 of 5...\n",
      "Processing chain 4 of 5...\n",
      "Processing chain 5 of 5...\n"
     ]
    }
   ],
   "source": [
    "# Find out which chains have been processed.\n",
    "\n",
    "# Read rows 2, 102, 202, ... from nn_X.csv until EOF.\n",
    "chain_ids = []\n",
    "with open(NN_X_OUTPUT_FILE_NAME, \"r\") as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    next(reader) # Skip the header.\n",
    "    try:\n",
    "        while True:\n",
    "            row = next(reader) # This is the first row of a chain.\n",
    "            chain_id = row[0]\n",
    "            chain_ids.append(chain_id)\n",
    "            for _ in range(99):\n",
    "                next(reader) # Skip the other 99 rows of this chain.\n",
    "    except StopIteration:\n",
    "        pass\n",
    "    \n",
    "print(chain_ids)\n",
    "\n",
    "# Write the header of nn_Y.csv.\n",
    "with open(NN_Y_OUTPUT_FILE_NAME, \"w\") as file:\n",
    "    file.write(\"chain_id,i,range,x,y,z,qw,qx,qy,qz\\n\")\n",
    "\n",
    "ground_truth = pd.read_csv(ABSOLUTE_PATH_TO_GROUND_TRUTH)\n",
    "\n",
    "# For an unknown reason, the header row's column names somehow have trailing whitespaces.\n",
    "# We remove them so we can index into columns.\n",
    "ground_truth.columns = ground_truth.columns.str.strip()\n",
    "\n",
    "# Format the first column \"chain_id\" as strings.\n",
    "ground_truth[\"chain_id\"] = ground_truth[\"chain_id\"].astype(str)\n",
    "\n",
    "for (index, chain_id) in enumerate(chain_ids):\n",
    "    print(f'Processing chain {index + 1} of 5...')\n",
    "\n",
    "    # Get the ground truth for this chain.\n",
    "    ground_truth_chain = ground_truth[ground_truth[\"chain_id\"] == chain_id]\n",
    "\n",
    "    # Note that ground_truth_chain DataFrame preserves the original row indices from ground_truth DataFrame.\n",
    "    # We reindex the ground truth chain's row numbers so we can use the new row index as a surrogate for the image number.\n",
    "    ground_truth_chain = ground_truth_chain.reset_index(drop=True)\n",
    "\n",
    "    # Decompose the net transformations into incremental transformations.\n",
    "\n",
    "    # Handle the first image -- the reference image.\n",
    "    with open(NN_Y_OUTPUT_FILE_NAME, \"a\") as file:\n",
    "        # Header: chain_id,i,x,y,z,qw,qx,qy,qz\n",
    "        file.write(f'{chain_id},0,0,0,0,1,0,0,0\\n')\n",
    "\n",
    "    # Then, for i from 1 to 99, we calculate the incremental transformation from image h = i - 1 to image i.\n",
    "    for i in range(1, 100):\n",
    "        \n",
    "        h = i - 1 # We choose the letter h because h is the letter before i.\n",
    "\n",
    "        from_0_to_h_rotation    = ground_truth_chain.loc[h, ['qw', 'qx', 'qy', 'qz']].values\n",
    "        from_0_to_h_translation = ground_truth_chain.loc[h, ['x', 'y', 'z']].values\n",
    "        from_0_to_i_rotation    = ground_truth_chain.loc[i, ['qw', 'qx', 'qy', 'qz']].values\n",
    "        from_0_to_i_translation = ground_truth_chain.loc[i, ['x', 'y', 'z']].values\n",
    "\n",
    "        from_h_to_i_rotation, from_h_to_i_translation = decompose_transformations(from_0_to_h_rotation, from_0_to_h_translation, from_0_to_i_rotation, from_0_to_i_translation)\n",
    "\n",
    "        with open(NN_Y_OUTPUT_FILE_NAME, \"a\") as file:\n",
    "            file.write(f'{chain_id},{i},{from_h_to_i_translation[0]},{from_h_to_i_translation[1]},{from_h_to_i_translation[2]},{from_h_to_i_rotation[0]},{from_h_to_i_rotation[1]},{from_h_to_i_rotation[2]},{from_h_to_i_rotation[3]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
